{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Neural Network classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REF\n",
    "\n",
    "* [모두를 위한 머신러닝/딥러닝 강의](https://hunkim.github.io/ml/)\n",
    "  - [lab-10-4-mnist_nn_deep.py](https://github.com/hunkim/DeepLearningZeroToAll/blob/master/lab-10-4-mnist_nn_deep.py)\n",
    "  - [lab-10-5-mnist_nn_dropout.py](https://github.com/hunkim/DeepLearningZeroToAll/blob/master/lab-10-5-mnist_nn_dropout.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets( \"MNIST_data/\", one_hot=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST training example size:  55000\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "tf.set_random_seed(777)\n",
    "nb_classes = 10\n",
    "image_shape = 28 * 28 \n",
    "nn_layer_size = 512\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 101\n",
    "batch_size = 100\n",
    "num_iterations = int( mnist.train.num_examples / batch_size )\n",
    "print( \"MNIST training example size: \", mnist.train.num_examples )\n",
    "\n",
    "# dropout (keep_prob) rate  0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder( tf.float32, [None, image_shape ])\n",
    "Y = tf.placeholder( tf.float32, [None, nb_classes ] )\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W1 = tf.get_variable(\"W_1\", shape=[ image_shape, nn_layer_size ], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable( tf.random_normal( [ nn_layer_size ] ) )\n",
    "L1 = tf.nn.relu( tf.matmul(X, W1) + b1 )\n",
    "L1 = tf.nn.dropout( L1, keep_prob=keep_prob )\n",
    "\n",
    "W2 = tf.get_variable(\"W_2\", shape=[ nn_layer_size, nn_layer_size ], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable( tf.random_normal( [ nn_layer_size ] ) )\n",
    "L2 = tf.nn.relu( tf.matmul(L1, W2) + b2 )\n",
    "L2 = tf.nn.dropout( L2, keep_prob=keep_prob )\n",
    "\n",
    "W3 = tf.get_variable(\"W_3\", shape=[ nn_layer_size, nn_layer_size ], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable( tf.random_normal( [ nn_layer_size ] ) )\n",
    "L3 = tf.nn.relu( tf.matmul(L2, W3) + b3 )\n",
    "L3 = tf.nn.dropout( L3, keep_prob=keep_prob )\n",
    "\n",
    "W4 = tf.get_variable(\"W_4\", shape=[ nn_layer_size, nn_layer_size ], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable( tf.random_normal( [ nn_layer_size ] ) )\n",
    "L4 = tf.nn.relu( tf.matmul(L3, W4) + b4 )\n",
    "L4 = tf.nn.dropout( L3, keep_prob=keep_prob )\n",
    "\n",
    "W5 = tf.get_variable(\"W_5\", shape=[ nn_layer_size, nb_classes ], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable( tf.random_normal( [ nb_classes ] ) )\n",
    "H = tf.matmul(L4, W5) + b5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis (using softmax)\n",
    "cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2( logits=H, labels=Y ) )\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Cost: 0.446349617\n",
      "Epoch: 0011, Cost: 0.052740080\n",
      "Epoch: 0021, Cost: 0.033689203\n",
      "Epoch: 0031, Cost: 0.028034579\n",
      "Epoch: 0041, Cost: 0.024578928\n",
      "Epoch: 0051, Cost: 0.021766443\n",
      "Epoch: 0061, Cost: 0.018829662\n",
      "Epoch: 0071, Cost: 0.019878834\n",
      "Epoch: 0081, Cost: 0.021220202\n",
      "Epoch: 0091, Cost: 0.020092990\n",
      "Epoch: 0101, Cost: 0.018759096\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() \n",
    "\n",
    "# Initialize TensorFlow variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(num_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        _, cost_val = sess.run( [ optimizer, cost ], feed_dict=feed_dict )\n",
    "        avg_cost += cost_val / num_iterations\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "print(\"Learning finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9827\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax( H, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean( tf.cast( correct_prediction, tf.float32 ) )\n",
    "\n",
    "print(\n",
    "    \"Accuracy: \",\n",
    "    accuracy.eval(\n",
    "        session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r : r + 1], 1)))\n",
    "print(\n",
    "    \"Prediction: \",\n",
    "    sess.run(tf.argmax( H, 1), feed_dict={X: mnist.test.images[r : r + 1], keep_prob: 1}),\n",
    ")\n",
    "\n",
    "plt.imshow(\n",
    "    mnist.test.images[r : r + 1].reshape(28, 28),\n",
    "    cmap=\"Greys\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
